The accompanying code is for the implementation of LLM-Check: Investigating Detection of Hallucinations in Large Language Models, a paper submitted to NeurIPS 2024 as part of the reviewing process.

Per NeurIPS guidelines, keep any submitted code and data in strict confidentiality and use it only for reviewing purposes. Do not distribute without acquiring licensing permission from authors.
